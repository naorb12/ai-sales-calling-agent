import { ChatOpenAI } from "@langchain/openai";
import { ChatPromptTemplate } from "@langchain/core/prompts";
import { z } from "zod";
import type { TimeSlot } from "../types.js";
import { config } from "../config.js";

/**
 * Schema for slot selection response
 */
const SlotSelectionSchema = z.object({
  selectedIndex: z.number().min(-1).describe("××™× ×“×§×¡ ×©×œ ×”×–××Ÿ ×©× ×‘×—×¨ (0-based), ××• -1 ×× ×œ× × ×‘×—×¨"),
  confidence: z.number().min(0).max(1).describe("×¨××ª ×‘×™×˜×—×•×Ÿ ×‘×‘×—×™×¨×”"),
  reasoning: z.string().describe("×”×¡×‘×¨ ×§×¦×¨ ×œ××” ×–×” ×”×–××Ÿ ×©× ×‘×—×¨"),
});

/**
 * Model for slot extraction - temperature 0 for deterministic extraction
 */
const slotModel = new ChatOpenAI({
  model: "gpt-4o-mini",
  temperature: 0,
  apiKey: config.openai.apiKey,
});

/**
 * Prompt for slot extraction
 */
const slotPrompt = ChatPromptTemplate.fromMessages([
  [
    "system",
    `××ª×” ×¢×•×–×¨ ×œ×–×”×•×ª ××™×–×” ×–××Ÿ ×¤×’×™×©×” ×”×œ×§×•×— ×‘×—×¨ ××ª×•×š ×¨×©×™××ª ××¤×©×¨×•×™×•×ª.

×ª×¤×§×™×“: ×œ×§×¨×•× ××ª ×ª×©×•×‘×ª ×”×œ×§×•×— ×•×œ×”×‘×™×Ÿ ××™×–×” ×–××Ÿ ×”×•× ×‘×—×¨.

×›×œ×œ×™×:
- ×× ×”×œ×§×•×— ×‘×—×¨ ×–××Ÿ ×¡×¤×¦×™×¤×™ â†’ ×”×—×–×¨ ××ª ×”××™× ×“×§×¡ ×©×œ×• (0-based)
- ×× ×”×œ×§×•×— ×œ× ×‘×—×¨ ×–××Ÿ ×¡×¤×¦×™×¤×™ â†’ ×”×—×–×¨ -1

×“×•×’×××•×ª ×œ×‘×—×™×¨×” ×¡×¤×¦×™×¤×™×ª:
- "×‘×¢×©×¨" â†’ ×–××Ÿ ×¢× 10:00
- "××—×¨ ×‘-10" â†’ ×–××Ÿ ×¢× 10:00 ××—×¨
- "×”××•×¤×¦×™×” ×”×¨××©×•× ×”" â†’ ××™× ×“×§×¡ 0
- "×”×©× ×™" â†’ ××™× ×“×§×¡ 1
- "14:00" â†’ ×–××Ÿ ×¢× 14:00
- "×™×•× ×©×œ×™×©×™" â†’ ×”×™×•× ×©×œ×™×©×™ (×× ×™×© ×¨×§ ××—×“)

×“×•×’×××•×ª ×œ×œ× ×‘×—×™×¨×” ×¡×¤×¦×™×¤×™×ª:
- "××ª×™ × ×•×— ×œ×›×?" â†’ -1 (×©×•××œ, ×œ× ×‘×•×—×¨)
- "××™×Ÿ ×œ×™ ×”×¢×“×¤×”" â†’ -1 (×œ× ×‘×—×¨)
- "×œ× ××©× ×”" â†’ -1 (×œ× ×‘×—×¨)
- "×‘×•×§×¨" â†’ -1 (×œ× ×¡×¤×¦×™×¤×™ ××¡×¤×™×§)

×—×©×•×‘: ×‘×—×¨ ×¨×§ ×× ×”×œ×§×•×— ×¦×™×™×Ÿ ×–××Ÿ **×¡×¤×¦×™×¤×™**!`,
  ],
  [
    "human",
    `×–×× ×™× ×–××™× ×™×:
{availableSlots}

×ª×©×•×‘×ª ×”×œ×§×•×—: "{userInput}"

××™×–×” ×–××Ÿ ×”×œ×§×•×— ×‘×—×¨? (×”×—×–×¨ ××™× ×“×§×¡, ××• -1 ×× ×œ× ×‘×—×¨ ×–××Ÿ ×¡×¤×¦×™×¤×™)`,
  ],
]);

/**
 * Extract selected slot using LLM semantic understanding
 */
export async function extractSelectedSlot(
  agentResponse: string,
  userInput: string,
  availableSlots: TimeSlot[]
): Promise<TimeSlot | null> {
  if (!availableSlots || availableSlots.length === 0) {
    return null;
  }

  // Don't try to extract if user didn't say anything meaningful
  if (!userInput || userInput.trim().length === 0) {
    return null;
  }

  try {
    // Format available slots for the LLM
    const slotsText = availableSlots
      .map((slot, i) => `${i}. ${slot.displayText}`)
      .join("\n");

    const chain = slotPrompt.pipe(slotModel.withStructuredOutput(SlotSelectionSchema));

    const result = await chain.invoke({
      availableSlots: slotsText,
      userInput,
    });

    // Log extraction result
    console.log(`\nğŸ• Slot Extraction:`);
    console.log(`   Selected Index: ${result.selectedIndex}`);
    console.log(`   Confidence: ${(result.confidence * 100).toFixed(0)}%`);
    console.log(`   Reasoning: ${result.reasoning}`);

    // If LLM found a selection
    if (result.selectedIndex >= 0 && result.selectedIndex < availableSlots.length) {
      const selectedSlot = availableSlots[result.selectedIndex];
      return selectedSlot ?? null;
    }

    return null;
  } catch (error) {
    console.error("Error extracting slot:", error);
    return null;
  }
}

